#!/usr/bin/env python3
# mypy: disable-error-code="misc,assignment,arg-type,attr-defined,index,return-value,union-attr,dict-item,operator"
"""
1-Hour Release Candidate Soak Test

Tests the autonomous learning loop for 1 hour with:
- Real telemetry monitoring
- Pattern learning tracking
- Healing attempt logging
- Budget limits for API calls
- Metrics dashboard

Constitutional Compliance:
- Article I: Complete context validation
- Article II: 100% test verification
- Article III: Automated enforcement
- Article IV: Continuous learning
- Article V: Spec-driven implementation
"""

import os
import sys
import time
import json
import random
import asyncio
import argparse
import subprocess
import time
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple

# Enable unified core
os.environ["ENABLE_UNIFIED_CORE"] = "true"

from core import get_core, get_learning_loop
from core.telemetry import get_telemetry, emit
from learning_loop import LearningLoop

REPO_ROOT = Path(__file__).resolve().parent


class SoakTestMonitor:
    """Monitor for 1-hour soak test."""

    def __init__(self, duration: int = 3600, budget: float = 10.0):
        """
        Initialize soak test monitor.

        Args:
            duration: Test duration in seconds (default 1 hour)
            budget: Maximum budget for API calls in dollars
        """
        self.duration = duration
        self.budget = budget
        self.start_time = None
        self.metrics = {
            "events_detected": 0,
            "patterns_learned": 0,
            "healing_attempts": 0,
            "healing_successes": 0,
            "api_calls": 0,
            "api_cost": 0.0,
            "errors": []
        }
        self.core = get_core()
        self.telemetry = get_telemetry()
        self.learning_loop = None

    async def run_soak_test(self):
        """Run the 1-hour soak test."""
        print("\n" + "=" * 60)
        print("üß™ 1-HOUR RELEASE CANDIDATE SOAK TEST")
        print("=" * 60)
        print(f"Duration: {self.duration} seconds ({self.duration / 3600:.1f} hours)")
        print(f"Budget: ${self.budget:.2f}")
        print(f"Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("-" * 60 + "\n")

        self.start_time = datetime.now()
        end_time = self.start_time + timedelta(seconds=self.duration)

        # Initialize learning loop if available (non-hanging, verbose fallbacks)
        try:
            self.learning_loop = get_learning_loop()
            if self.learning_loop and hasattr(self.learning_loop, "start"):
                try:
                    # Avoid hanging per rules: bounded startup
                    await asyncio.wait_for(self.learning_loop.start(), timeout=5.0)
                    print("‚úÖ Learning loop started")
                except asyncio.TimeoutError:
                    print("‚ö†Ô∏è  Learning loop start timed out after 5s; proceeding without it")
                    self.learning_loop = None
            else:
                print("‚ö†Ô∏è  Learning loop not available or missing 'start' method; proceeding without it")
                self.learning_loop = None
        except Exception as e:
            print(f"‚ö†Ô∏è  Learning loop not available: {e}")
            self.learning_loop = None

        # Main monitoring loop
        iteration = 0
        while datetime.now() < end_time:
            iteration += 1
            elapsed = (datetime.now() - self.start_time).total_seconds()
            remaining = self.duration - elapsed

            # Print status every minute
            if iteration % 60 == 0:
                self.print_status(elapsed, remaining)

            # Simulate various events
            if iteration % 10 == 0:
                await self.simulate_event()

            # Check budget
            if self.metrics["api_cost"] >= self.budget:
                print(f"\nüí∞ Budget limit reached: ${self.metrics['api_cost']:.2f}")
                break

            # Check for real events
            await self.check_real_events()

            # Sleep for 1 second
            await asyncio.sleep(1)

        # Stop learning loop (bounded, best-effort)
        if self.learning_loop and hasattr(self.learning_loop, "stop"):
            try:
                await asyncio.wait_for(self.learning_loop.stop(), timeout=5.0)
                print("\n‚úÖ Learning loop stopped")
            except asyncio.TimeoutError:
                print("\n‚ö†Ô∏è  Learning loop stop timed out after 5s; continuing shutdown")
        elif self.learning_loop:
            print("\n‚ö†Ô∏è  Learning loop lacks 'stop' method; skipping shutdown step")

        # Final report
        self.print_final_report()

    async def simulate_event(self):
        """Simulate various system events for testing."""
        event_types = [
            "file_modified",
            "error_detected",
            "test_failure",
            "pattern_matched"
        ]

        event_type = random.choice(event_types)
        self.metrics["events_detected"] += 1

        # Log the event
        emit(f"soak_test_{event_type}", {
            "iteration": self.metrics["events_detected"],
            "timestamp": datetime.now().isoformat()
        })

        # Simulate API call cost (rough estimates)
        if event_type == "error_detected":
            self.metrics["healing_attempts"] += 1
            self.metrics["api_calls"] += 1
            self.metrics["api_cost"] += 0.02  # Rough estimate per API call

            # Simulate success/failure
            if random.random() > 0.3:  # 70% success rate
                self.metrics["healing_successes"] += 1

        elif event_type == "pattern_matched":
            self.metrics["patterns_learned"] += 1

    async def check_real_events(self):
        """Check for real events in the system."""
        try:
            # Check telemetry for recent events
            metrics = self.telemetry.get_metrics()

            # Update our metrics from real data
            if "errors" in metrics:
                error_count = metrics["errors"]
                if error_count > 0:
                    self.metrics["events_detected"] += 1

        except Exception as e:
            self.metrics["errors"].append(str(e))

    def print_status(self, elapsed: float, remaining: float):
        """Print current status."""
        print(f"\nüìä Status Update - {datetime.now().strftime('%H:%M:%S')}")
        print(f"   Elapsed: {elapsed:.0f}s | Remaining: {remaining:.0f}s")
        print(f"   Events: {self.metrics['events_detected']} | "
              f"Patterns: {self.metrics['patterns_learned']} | "
              f"Heals: {self.metrics['healing_successes']}/{self.metrics['healing_attempts']}")
        print(f"   API Cost: ${self.metrics['api_cost']:.2f} / ${self.budget:.2f}")

        # Check system health
        health = self.core.get_health_status()
        print(f"   System Health: {health['status']} ({health['health_score']:.1f}%)")

    def print_final_report(self):
        """Print final soak test report."""
        duration = (datetime.now() - self.start_time).total_seconds()

        print("\n" + "=" * 60)
        print("üìã SOAK TEST FINAL REPORT")
        print("=" * 60)

        print(f"\n‚è±Ô∏è  Duration: {duration:.0f} seconds ({duration / 60:.1f} minutes)")
        print(f"üéØ Events Detected: {self.metrics['events_detected']}")
        print(f"üìö Patterns Learned: {self.metrics['patterns_learned']}")
        print(f"üè• Healing Success Rate: ", end="")

        success_rate = 0.0  # default when there are no attempts
        if self.metrics['healing_attempts'] > 0:
            success_rate = (self.metrics['healing_successes'] /
                            self.metrics['healing_attempts']) * 100
            print(f"{success_rate:.1f}% "
                  f"({self.metrics['healing_successes']}/{self.metrics['healing_attempts']})")
        else:
            print("No healing attempts")

        print(f"üí∞ API Usage: ${self.metrics['api_cost']:.2f} / ${self.budget:.2f}")
        print(f"üìû API Calls: {self.metrics['api_calls']}")

        if self.metrics['errors']:
            print(f"\n‚ö†Ô∏è  Errors Encountered: {len(self.metrics['errors'])}")
            for error in self.metrics['errors'][:5]:  # Show first 5 errors
                print(f"   - {error}")

        # System health at end
        health = self.core.get_health_status()
        print(f"\nüè• Final System Health:")
        print(f"   Status: {health['status']}")
        print(f"   Health Score: {health['health_score']:.1f}%")
        print(f"   Pattern Count: {health['pattern_count']}")
        print(f"   Recent Errors: {health['recent_errors']}")

        # Verdict
        print("\n" + "-" * 60)
        if success_rate >= 60 and health['health_score'] >= 80:
            print("‚úÖ SOAK TEST PASSED")
            print("   The system maintained stability and learning capability")
        else:
            print("‚ö†Ô∏è  SOAK TEST COMPLETED WITH ISSUES")
            print("   Review metrics and address any failures before release")

        print("-" * 60 + "\n")

        # Save report to file
        report_file = f"soak_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump({
                "duration": duration,
                "metrics": self.metrics,
                "health": health,
                "timestamp": datetime.now().isoformat()
            }, f, indent=2)
        print(f"üìÑ Full report saved to: {report_file}")


def _execute_verification_script(report: Optional[str], markdown: bool, timeout_seconds: int) -> Tuple[int, Path, Optional[Path]]:
    """Execute the verify_soak.py script and return results.

    Returns:
        Tuple of (exit_code, json_output_path, markdown_output_path)
    """
    analysis_dir = REPO_ROOT / "logs" / "analysis"
    analysis_dir.mkdir(parents=True, exist_ok=True)
    ts = time.strftime("%Y%m%d_%H%M%S", time.gmtime())
    json_out = analysis_dir / f"soak_verification_{ts}.json"

    cmd = [
        sys.executable,
        str(REPO_ROOT / "commands" / "verify_soak.py"),
        "--output", str(json_out),
    ]
    if report:
        cmd += ["--report", report]
    if markdown:
        cmd += ["--markdown"]

    env = os.environ.copy()
    env["PERSIST_PATTERNS"] = "true"

    try:
        res = subprocess.run(cmd, cwd=str(REPO_ROOT), env=env, text=True, capture_output=True, timeout=timeout_seconds, check=False)
    except subprocess.TimeoutExpired:
        print("‚ùå verify_soak.py timed out; aborting", file=sys.stderr)
        return 1, json_out, None

    if res.returncode != 0:
        print("‚ùå verify_soak.py failed:")
        print(res.stdout)
        print(res.stderr, file=sys.stderr)
        return 1, json_out, None

    md_path = analysis_dir / json_out.name.replace(".json", ".md") if markdown else None
    return 0, json_out, md_path


def _publish_to_dashboard(json_out: Path, md_path: Optional[Path]) -> bool:
    """Publish results to dashboard by creating symlinks and emitting telemetry.

    Returns:
        True if successful, False if partial failure
    """
    analysis_dir = json_out.parent
    ok = True

    def _link_or_copy(src: Optional[Path], dest_name: str):
        nonlocal ok
        if not src or not src.exists():
            return
        dest = analysis_dir / dest_name
        try:
            if dest.exists() or dest.is_symlink():
                dest.unlink()
        except Exception:
            pass
        try:
            dest.symlink_to(src)
        except Exception:
            try:
                import shutil as _sh
                _sh.copy2(src, dest)
            except Exception:
                ok = False

    _link_or_copy(json_out, "latest_soak_verification.json")
    _link_or_copy(md_path, "latest_soak_verification.md")

    try:
        emit("soak_verification_posted", {
            "json": str(json_out) if json_out.exists() else None,
            "markdown": str(md_path) if (md_path and md_path.exists()) else None,
            "channel": "dashboard"
        })
    except Exception:
        pass

    return ok


def _check_github_cli_available() -> bool:
    """Check if GitHub CLI is available.

    Returns:
        True if gh CLI is available, False otherwise
    """
    try:
        r = subprocess.run(["gh", "--version"], capture_output=True, text=True)
        return r.returncode == 0
    except Exception:
        return False


def _parse_repository_info(repo: Optional[str]) -> Tuple[Optional[str], Optional[str]]:
    """Parse repository information from input or environment.

    Args:
        repo: Repository in format "owner/name" or None

    Returns:
        Tuple of (owner, name) or (None, None) if parsing fails
    """
    if not repo:
        rep = os.environ.get("GITHUB_REPOSITORY")
        if rep and "/" in rep:
            owner, name = rep.split("/", 1)
            return owner, name
        return None, None
    if "/" not in repo:
        return None, None
    owner, name = repo.split("/", 1)
    return owner, name


def _auto_detect_pr_number(current_pr: Optional[int]) -> Optional[int]:
    """Auto-detect PR number from GitHub event if not provided."""
    if current_pr:
        return current_pr

    event_path = os.environ.get("GITHUB_EVENT_PATH")
    if event_path and Path(event_path).exists():
        try:
            data = json.loads(Path(event_path).read_text())
            return data.get("number") or data.get("pull_request", {}).get("number")
        except Exception:
            pass
    return None


def _post_via_github_api(md_file: Path, pr_number: int, owner: str, name: str) -> bool:
    """Post comment via GitHub REST API."""
    token = os.environ.get("GITHUB_TOKEN")
    if not token:
        print("‚ö†Ô∏è  No gh CLI and no GITHUB_TOKEN available ‚Äî cannot post PR comment.")
        return False

    import urllib.request, urllib.error
    api = f"https://api.github.com/repos/{owner}/{name}/issues/{pr_number}/comments"
    body = json.dumps({"body": md_file.read_text()}).encode("utf-8")
    req = urllib.request.Request(api, data=body, method="POST")
    req.add_header("Authorization", "token " + token)
    req.add_header("Accept", "application/vnd.github+json")
    req.add_header("Content-Type", "application/json")

    try:
        with urllib.request.urlopen(req, timeout=10) as resp:
            return 200 <= resp.status < 300
    except Exception as e:
        print(f"‚ùå GitHub API error: {e}", file=sys.stderr)
        return False


def _post_pr_comment(md_file: Path, pr_number: Optional[int], repo: Optional[str]) -> bool:
    """Post comment to a GitHub Pull Request.

    Args:
        md_file: Path to markdown file to post
        pr_number: PR number or None to auto-detect
        repo: Repository in format "owner/name"

    Returns:
        True if successful, False otherwise
    """
    owner, name = _parse_repository_info(repo)
    local_pr = _auto_detect_pr_number(pr_number)

    if _check_github_cli_available():
        if not local_pr:
            print("‚ö†Ô∏è  Cannot infer PR number. Provide --pr-number.")
            return False
        cmd = ["gh", "pr", "comment", str(local_pr), "-F", str(md_file)]
        if owner and name:
            cmd += ["--repo", f"{owner}/{name}"]
        r = subprocess.run(cmd, text=True)
        return r.returncode == 0

    # Fallback to REST API
    if not (owner and name and local_pr):
        print("‚ö†Ô∏è  Missing --repo owner/repo or --pr-number for REST API posting.")
        return False

    return _post_via_github_api(md_file, local_pr, owner, name)


def _post_issue_comment(md_file: Path, issue_number: Optional[int], repo: Optional[str]) -> bool:
    """Post comment to a GitHub Issue.

    Args:
        md_file: Path to markdown file to post
        issue_number: Issue number
        repo: Repository in format "owner/name"

    Returns:
        True if successful, False otherwise
    """
    owner, name = _parse_repository_info(repo)

    if _check_github_cli_available():
        if not issue_number:
            print("‚ö†Ô∏è  Provide --issue-number to post to an issue.")
            return False
        cmd = ["gh", "issue", "comment", str(issue_number), "-F", str(md_file)]
        if owner and name:
            cmd += ["--repo", f"{owner}/{name}"]
        r = subprocess.run(cmd, text=True)
        return r.returncode == 0

    # Fallback to REST API
    token = os.environ.get("GITHUB_TOKEN")
    if not token:
        print("‚ö†Ô∏è  No gh CLI and no GITHUB_TOKEN available ‚Äî cannot post issue comment.")
        return False
    if not (owner and name and issue_number):
        print("‚ö†Ô∏è  Missing --repo owner/repo or --issue-number for REST API posting.")
        return False

    import urllib.request, urllib.error
    api = f"https://api.github.com/repos/{owner}/{name}/issues/{issue_number}/comments"
    body = json.dumps({"body": md_file.read_text()}).encode("utf-8")
    req = urllib.request.Request(api, data=body, method="POST")
    req.add_header("Authorization", "token " + token)
    req.add_header("Accept", "application/vnd.github+json")
    req.add_header("Content-Type", "application/json")

    try:
        with urllib.request.urlopen(req, timeout=10) as resp:
            return 200 <= resp.status < 300
    except Exception as e:
        print(f"‚ùå GitHub API error: {e}", file=sys.stderr)
        return False


def _verify_soak(report: Optional[str], channel: str, markdown: bool, pr_number: Optional[int], issue_number: Optional[int], repo: Optional[str], timeout_seconds: int) -> int:
    """Run verify_soak.py and publish results to a channel.

    Returns an exit code (0 success, non-zero on posting failures).
    """
    # Execute verification script
    exit_code, json_out, md_path = _execute_verification_script(report, markdown, timeout_seconds)
    if exit_code != 0:
        return exit_code

    # Route to appropriate publishing method
    if channel == "dashboard":
        ok = _publish_to_dashboard(json_out, md_path)
        print(f"‚úÖ Dashboard update: {'ok' if ok else 'partial'} ‚Äî {json_out}")
        return 0 if ok else 2
    else:
        if not md_path or not md_path.exists():
            print("‚ö†Ô∏è  Markdown output is required for PR/issue comment. Re-run with --markdown.")
            return 2

        posted = _post_pr_comment(md_path, pr_number, repo) if channel == "pr" else _post_issue_comment(md_path, issue_number, repo)

        try:
            emit("soak_verification_posted", {
                "json": str(json_out),
                "markdown": str(md_path),
                "channel": channel,
                "posted": posted,
            })
        except Exception:
            pass

        if not posted:
            print("‚ö†Ô∏è  Failed to post comment. See guidance above for creds or gh CLI.")
            return 3
        print("‚úÖ Posted verification results")
        return 0


def main():
    """Main entry point for soak test."""
    parser = argparse.ArgumentParser(description="1-Hour Release Candidate Soak Test")
    parser.add_argument(
        "--duration",
        type=int,
        default=3600,
        help="Test duration in seconds (default: 3600 = 1 hour)"
    )
    parser.add_argument(
        "--budget",
        type=float,
        default=10.0,
        help="Maximum budget for API calls in dollars (default: 10.0)"
    )
    # Verification/reporting integration (lean)
    parser.add_argument("--verify-soak", action="store_true", help="Run soak verification and publish results instead of running the soak loop")
    parser.add_argument("--report", type=str, help="Path to soak report JSON produced by the soak test")
    parser.add_argument("--markdown", action="store_true", help="Also generate Markdown output for publishing")
    parser.add_argument("--channel", choices=["dashboard", "pr", "issue"], default="dashboard", help="Where to publish results")
    parser.add_argument("--pr-number", type=int, help="Pull Request number for PR channel")
    parser.add_argument("--issue-number", type=int, help="Issue number for issue channel")
    parser.add_argument("--repo", type=str, help="owner/repo to target for PR/issue channels (defaults to GITHUB_REPOSITORY)")
    parser.add_argument("--timeout-seconds", type=int, default=120, help="Timeout for verify_soak.py execution")

    args = parser.parse_args()

    if args.verify_soak:
        code = _verify_soak(
            report=args.report,
            channel=args.channel,
            markdown=args.markdown,
            pr_number=args.pr_number,
            issue_number=args.issue_number,
            repo=args.repo,
            timeout_seconds=args.timeout_seconds,
        )
        sys.exit(code)

    # Create and run monitor
    monitor = SoakTestMonitor(duration=args.duration, budget=args.budget)

    # Run the async soak test
    asyncio.run(monitor.run_soak_test())


if __name__ == "__main__":
    main()