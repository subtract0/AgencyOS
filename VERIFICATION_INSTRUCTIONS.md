# ğŸ” Monastery 0.8.0 Beta - Feature Verification Instructions

This document provides comprehensive instructions for verifying all claimed features in Monastery 0.8.0 Beta release.

## ğŸ“‹ Manual Verification Checklist

### 1. ğŸ¥ Autonomous Healing System (CRITICAL)

**This is the KEY differentiator - must work!**

```bash
# Test 1: Run the autonomous healing demo
python demo_autonomous_healing.py

# Expected: Complete demo showing:
# - Error detection from logs
# - LLM-powered fix generation
# - Patch application workflow
# - Test verification process

# Test 2: Check autonomous healing tools exist
python -c "from tools.auto_fix_nonetype import AutoNoneTypeFixer, NoneTypeErrorDetector, LLMNoneTypeFixer; print('âœ… Healing tools available')"

# Test 3: Check orchestration components
python -c "from tools.apply_and_verify_patch import ApplyAndVerifyPatch, AutonomousHealingOrchestrator; print('âœ… Orchestration available')"

# Test 4: Verify healing logs directory
ls -la logs/autonomous_healing/ 2>/dev/null || echo "No healing logs yet"
```

**âœ… PASS Criteria:**
- Demo runs without crashes
- All healing tools import successfully
- Orchestration components available
- Error detection works on sample logs

**âŒ FAIL Indicators:**
- ImportError on healing tools
- Demo crashes or doesn't show healing workflow
- Missing core components

### 2. ğŸ¤– Multi-Agent Architecture (10 Agents)

```bash
# Test 1: Verify all 10 agents can be imported
python -c "
try:
    from chief_architect_agent import create_chief_architect_agent
    from agency_code_agent.agency_code_agent import create_agency_code_agent
    from planner_agent.planner_agent import create_planner_agent
    from auditor_agent import create_auditor_agent
    from test_generator_agent import create_test_generator_agent
    from learning_agent import create_learning_agent
    from merger_agent.merger_agent import create_merger_agent
    from toolsmith_agent import create_toolsmith_agent
    from work_completion_summary_agent import create_work_completion_summary_agent
    from quality_enforcer_agent import create_quality_enforcer_agent
    print('âœ… All 10 agents importable')
except ImportError as e:
    print(f'âŒ Agent import failed: {e}')
"

# Test 2: Test agent creation (with safe model)
python -c "
from agency_code_agent.agency_code_agent import create_agency_code_agent
from planner_agent.planner_agent import create_planner_agent
try:
    coder = create_agency_code_agent(model='gpt-4', reasoning_effort='low')
    planner = create_planner_agent(model='gpt-4', reasoning_effort='low')
    print('âœ… Core agents can be created')
except Exception as e:
    print(f'âŒ Agent creation failed: {e}')
"

# Test 3: Interactive agency test (requires manual interaction)
# sudo python agency.py
# Try: "Create a simple Python function to calculate fibonacci"
# Should see: Planner â†’ Coder workflow
```

**âœ… PASS Criteria:**
- All 10 agents import without errors
- Core agents can be instantiated
- Agency interactive mode works
- Agent handoffs function

**âŒ FAIL Indicators:**
- Missing agent modules
- Creation failures
- No agent communication

### 3. ğŸ§  Memory & Learning System

```bash
# Test 1: Basic memory functionality
python -c "
from agency_memory import Memory, InMemoryStore
memory = Memory(store=InMemoryStore())
memory.store('test', {'data': 'value'}, tags=['test'])
result = memory.get('test')
assert result['data'] == 'value'
print('âœ… Basic memory works')
"

# Test 2: Memory search and tagging
python -c "
from agency_memory import Memory, InMemoryStore
memory = Memory(store=InMemoryStore())
memory.store('item1', {'type': 'error'}, tags=['error', 'fix'])
memory.store('item2', {'type': 'success'}, tags=['success', 'fix'])
results = memory.search(tags=['fix'])
assert len(results) >= 2
print('âœ… Memory search works')
"

# Test 3: Learning consolidation
python -c "
from agency_memory import consolidate_learnings, Memory, InMemoryStore
memory = Memory(store=InMemoryStore())
memory.store('learn1', {'pattern': 'test'}, tags=['learning'])
report = consolidate_learnings(memory.store)
print('âœ… Learning consolidation works')
"

# Test 4: Session transcripts
ls -la logs/sessions/ 2>/dev/null && echo "âœ… Session transcripts directory exists" || echo "âŒ No session transcripts"

# Test 5: Enhanced memory (VectorStore)
python -c "
try:
    from agency_memory import EnhancedMemoryStore, create_enhanced_memory_store
    store = create_enhanced_memory_store()
    print('âœ… Enhanced memory available')
except Exception as e:
    print(f'âš ï¸ Enhanced memory not fully available: {e}')
"
```

**âœ… PASS Criteria:**
- Basic memory operations work
- Tagging and search functional
- Learning consolidation available
- Session transcript system exists

**âŒ FAIL Indicators:**
- Memory operations fail
- No session logging
- Learning system broken

### 4. ğŸ›ï¸ Constitutional Governance

```bash
# Test 1: Constitution file exists
ls -la constitution.md && echo "âœ… Constitution exists" || echo "âŒ No constitution"

# Test 2: Constitution content validation
grep -E "Article [I-V]" constitution.md && echo "âœ… All 5 articles present" || echo "âŒ Missing articles"

# Test 3: 100% test claim verification
python run_tests.py 2>&1 | tee test_results.txt
grep -i "all tests passed\|100%\|âœ…" test_results.txt && echo "âœ… Tests pass" || echo "âŒ Test failures"

# Test 4: Constitutional enforcement hooks
python -c "
try:
    # Check if constitutional validation exists in agents
    import constitution  # If this module exists
    print('âœ… Constitutional enforcement available')
except ImportError:
    print('âš ï¸ Constitutional enforcement module not found')
"
```

**âœ… PASS Criteria:**
- Constitution file exists with all 5 articles
- Test suite actually achieves 100% pass rate
- Constitutional enforcement mechanisms present

**âŒ FAIL Indicators:**
- Missing constitution file
- Test failures present
- No enforcement mechanisms

### 5. ğŸ’» CLI Commands (World-Class UX)

```bash
# Test 1: Health command
python agency.py health
echo "Exit code: $?"

# Test 2: Logs command
python agency.py logs

# Test 3: Test command
timeout 30s python agency.py test || echo "Test command timed out (expected)"

# Test 4: Demo command
timeout 10s python agency.py demo || echo "Demo command started (expected timeout)"

# Test 5: Legacy CLI script
ls -la agency_cli && echo "âœ… Legacy CLI exists" || echo "âš ï¸ No legacy CLI"

# Test 6: Help/usage
python agency.py --help
```

**âœ… PASS Criteria:**
- All commands run without immediate errors
- Health command shows system status
- Logs command displays recent activity
- Commands provide useful output

**âŒ FAIL Indicators:**
- Commands crash immediately
- No output or error messages
- Missing CLI functionality

### 6. ğŸ› ï¸ Development Tools (40+ Tools Claimed)

```bash
# Test 1: Core file tools
python -c "
from tools import Read, Write, Edit, MultiEdit
print('âœ… File operations available')
"

# Test 2: Search tools
python -c "
from tools import Grep, Glob
print('âœ… Search tools available')
"

# Test 3: System tools
python -c "
from tools import Bash, TodoWrite
print('âœ… System tools available')
"

# Test 4: Specialized tools
python -c "
try:
    from tools import Git, NotebookRead, NotebookEdit
    print('âœ… Specialized tools available')
except ImportError as e:
    print(f'âš ï¸ Some specialized tools missing: {e}')
"

# Test 5: Tool count verification
python -c "
import tools
tool_count = len([name for name in dir(tools) if not name.startswith('_')])
print(f'ğŸ“Š Tool count: {tool_count}')
if tool_count >= 20:
    print('âœ… Substantial tool set available')
else:
    print('âš ï¸ Fewer tools than expected')
"

# Test 6: Tool functionality test
python -c "
from tools import Read, Write, Bash
import tempfile, os

# Test file operations
test_file = os.path.join(tempfile.gettempdir(), 'tool_test.txt')
Write().run(file_path=test_file, content='Hello Tools')
content = Read().run(file_path=test_file)
assert 'Hello Tools' in content

# Test bash
result = Bash().run(command='echo Tool Test')
assert 'Tool Test' in result

print('âœ… Tools functionally work')
os.remove(test_file)
"
```

**âœ… PASS Criteria:**
- All core tool categories available
- Tools actually function (not just import)
- Substantial tool count (20+ tools)
- File operations work correctly

**âŒ FAIL Indicators:**
- Missing core tools
- Tools don't actually work
- Very low tool count

## ğŸ§ª Automated MasterTest Execution

After completing manual verification:

```bash
# Run the comprehensive automated test suite
python -m pytest tests/test_master_e2e.py -v --tb=short

# Or run directly
python tests/test_master_e2e.py
```

## ğŸ“Š Expected Results

### ğŸ¯ Success Criteria (Monastery 0.8.0 Beta)

- **Autonomous Healing**: âœ… Core tools work, demo runs
- **Multi-Agent**: âœ… At least 8/10 agents functional
- **Memory System**: âœ… Basic memory + learning works
- **Constitutional**: âœ… Constitution exists, most tests pass
- **CLI Commands**: âœ… All major commands functional
- **Development Tools**: âœ… 20+ tools available and working

### âš ï¸ Acceptable Beta Limitations

- Enhanced memory/VectorStore may have dependency issues
- Some specialized tools may be missing
- Test suite may not be exactly 100% (close to 100%)
- Advanced features may be experimental

### âŒ Critical Failures (Must Fix)

- Autonomous healing tools completely missing
- Core agents can't be created
- Memory system broken
- CLI commands crash
- Basic file tools don't work

## ğŸ› Known Issues to Check

Based on the codebase analysis, these are likely problem areas:

1. **QualityEnforcerAgent**: May not be fully implemented
2. **Enhanced Memory**: VectorStore dependencies might be missing
3. **Autonomous Healing Integration**: Tools exist but may not be fully wired
4. **CLI Command Modules**: Some commands may reference missing modules
5. **Test Suite**: Probably not actually at 100% pass rate

## ğŸ“‹ Verification Report Template

Use this template to document your verification results:

```markdown
# Monastery 0.8.0 Beta Verification Report

**Date**: [DATE]
**Verifier**: [NAME]
**Version**: Monastery 0.8.0 Beta

## Manual Verification Results

| Feature | Status | Notes |
|---------|--------|-------|
| ğŸ¥ Autonomous Healing | âœ…/âŒ | [Details] |
| ğŸ¤– Multi-Agent (10) | âœ…/âŒ | [X/10 agents working] |
| ğŸ§  Memory System | âœ…/âŒ | [Details] |
| ğŸ›ï¸ Constitutional | âœ…/âŒ | [Test pass rate: X%] |
| ğŸ’» CLI Commands | âœ…/âŒ | [Details] |
| ğŸ› ï¸ Dev Tools | âœ…/âŒ | [X tools found] |

## Automated Test Results

```
[Paste MasterTest output here]
```

## Critical Issues Found

1. [Issue description]
2. [Issue description]

## Recommendations

- [Priority 1 fix]
- [Priority 2 fix]

## Overall Assessment

Beta quality: âœ… Ready / âš ï¸ Needs work / âŒ Not ready

Key strengths: [List]
Key gaps: [List]
```

## ğŸš€ Quick Start Verification

For a rapid verification (5 minutes):

```bash
# 1. Quick healing check
python -c "from tools.auto_fix_nonetype import AutoNoneTypeFixer; print('âœ… Healing')"

# 2. Quick agent check
python -c "from agency_code_agent.agency_code_agent import create_agency_code_agent; print('âœ… Agents')"

# 3. Quick memory check
python -c "from agency_memory import Memory; print('âœ… Memory')"

# 4. Quick tools check
python -c "from tools import Read, Write, Bash; print('âœ… Tools')"

# 5. Quick CLI check
python agency.py health

echo "ğŸ¯ Rapid verification complete!"
```

This verification process will definitively validate whether Monastery 0.8.0 Beta delivers on its promises or identify gaps that need addressing before 1.0.