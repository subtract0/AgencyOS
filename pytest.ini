[pytest]
pythonpath = .

# ============================================================================
# STATE-OF-THE-ART TEST MARKERS
# ============================================================================
markers =
    unit: marks tests as unit tests (fast, isolated, mocked externals, <2s)
    integration: marks tests as integration tests (component interactions, <10s)
    e2e: marks end-to-end tests (full system scenarios, <30s)
    smoke: marks critical path tests for rapid TDD feedback (<30s total suite)
    slow: marks slow tests that may take longer to run (>1s, needs optimization)
    benchmark: marks benchmark performance tests (>1min allowed)
    github: marks tests requiring GitHub API access
    asyncio: mark test as async (used by pytest-asyncio)
    timeout: marks tests with custom timeout (requires pytest-timeout)

testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# ============================================================================
# DEFAULT BEHAVIOR: FAST TDD FEEDBACK LOOP
# ============================================================================
# By default, run only unit tests for <3 minute feedback cycle
# This is the state-of-the-art approach for Test-Driven Development
#
# Usage patterns:
#   pytest                  → Unit tests only (fast, <3 min)
#   pytest -m "unit"        → Explicit unit tests
#   pytest -m "integration" → Integration tests only
#   pytest -m "e2e"         → End-to-end tests only
#   pytest -m "smoke"       → Critical path smoke tests (<30s)
#   pytest -m "not slow"    → Skip slow tests needing optimization
#   pytest tests/           → ALL tests (full validation, 5-10 min)
#
# The default ensures developers get rapid feedback without waiting
# for slow integration/e2e tests during the TDD red-green-refactor cycle.
addopts =
    -q
    --strict-markers
    --tb=short
    --color=yes
    -m "unit"

# ============================================================================
# PERFORMANCE OPTIMIZATION SETTINGS
# ============================================================================
# Parallel execution: Install pytest-xdist for -n auto (pip install pytest-xdist)
# Timeout enforcement: Install pytest-timeout (pip install pytest-timeout)
# Auto-categorization: conftest.py adds markers by directory
# Global mocking: conftest.py mocks OpenAI/Firestore in unit tests

asyncio_mode = auto

# ============================================================================
# WARNING FILTERS
# ============================================================================
filterwarnings =
    ignore::DeprecationWarning
    ignore::pytest.PytestUnraisableExceptionWarning
    ignore::ResourceWarning

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================
# Harden pytest logging for cross-runner compatibility
# Route log file to a repo path instead of /dev/null
log_file = logs/pytest.log
log_file_level = WARNING
log_file_format = %(asctime)s %(levelname)s %(name)s: %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Console logging (only show warnings/errors during test runs)
log_cli = false
log_cli_level = WARNING
